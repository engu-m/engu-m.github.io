---
title: "Escape room üîê"
excerpt: "An RL agent tries to escape a room and gets stuck."
header:
  image: /assets/images/header_escape_room.jpg
  teaser: /assets/images/header_escape_room-th.jpg
video_src: /assets/videos/Slideshow_Escape_Room_Project.mp4
room_img: /assets/images/rooms.png
---

<link href={{page.monokai_css}} rel="stylesheet"/>
<link href={{page.base_style_css}} rel="stylesheet"/>


<h2>Introduction</h2>

<p>
  This project is a little game where the player has to escape from a room using the directional keys. Seven rooms were designed, with increasing difficulty. It takes less than a minute for a human to solve all levels. But the true goal of the project is to use a computer to solve these levels programmatically. This is achieved using techniques known as Reinforcement Learning, where one trains an "agent" to solve a challenge using trial and error. The agent is free to perform all actions, provided it stays within the bounds of the room. What the agent decides to do is called its policy.
</p>
  
<p>
  In this game, the player is represented by the letter <span style="color: #66D9EF" class="dark-bg" >P</span>. The <span style="color: #F92672" class="dark-bg" >X</span> are obstacles that the player cannot cross. The door <span style="color: #A6E22E" class="dark-bg" >D</span>, open by default, may require the use of a key <span style="color: #E6DB74" class="dark-bg" >K</span>
</p>

<p>Below are the seven rooms for this project.</p>

<figure>
  <img src={{page.room_img}} alt="View of the seven rooms as shown on a terminal" class="dark-border">
  <caption>A view of every room</caption>
</figure>

<h2>Video showcase</h2>

Because a picture is worth a thousand words, please find a presentation and demonstration below illustrating the whole learning process:

<video src={{page.video_src}} width="700" controls></video>

<h2>Technical considerations</h2>

<p>The learning agents proposed are using the standard "Q-learning" and "Expected SARSA" approaches.</p>

<p>In the current implementation, there are only three rewards possible :
<ul>
  <li>+10 if the agent solves the room, i.e. stands on the door cell, with the key in its possession if required </li>
  <li>+1 if the agent takes possession of the key, required to solve the room </li>
  <li>-1 otherwise</li>
</ul>
</p>

<p>The room definition is fully modular and can be changed at will. The width <code>w</code> and the height <code>h</code> of the room can be changed. Moreover, common location indications such as <code>"top"</code>, <code>"right"</code>, <code>"middle"</code> are understood. For example, the last room is simply defined in the code as a dictionary :
</p>

{% highlight python %}
{
  "door_location": "top-left",
  "key_location": "bottom-right",
  "agent_location": "bottom-middle",
  "obstacle_locations": [(1, w // 2), "top-right", "bottom-left"],
  "need_key": True,
}
{% endhighlight %}

<p>
This allows for flexible experiment settings.
</p>

<h2>Concusion</h2>

<p>
  Two Reinforcement Learning agents have successfully been implemented in a modular environment. Both agents showed similar behaviours and were quick to learn the optimal policy. This could further be improved by providing the agent with more information on the environment than the sole current reward: by giving as input a screenshot of the game at every step, one could get closer to human behaviour, like DeepMind did by solving the Atari games.
</p>

<p>
Full code and pdf report available on <a href="https://github.com/engu-m/Escape-room">github</a>.
</p>
